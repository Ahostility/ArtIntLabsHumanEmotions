{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gqzBaEQ0lRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1d65420e-bff7-4e8b-cceb-30329ab15edb"
      },
      "source": [
        "# 1. Tell Git about yourself:\n",
        "from getpass import getpass\n",
        "u = input('Username: ') # Git username\n",
        "p = getpass('Password: ') # Git password\n",
        "m = input('E-mail: ') # Git e-mail\n",
        "b = input('Branch: ') # Branch you need"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Username: mdmeldon\n",
            "Password: ··········\n",
            "E-mail: mdmeldon@gmail.com\n",
            "Branch: sound\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg2KgUx20m7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e23098e2-2adb-45df-f80a-036a95fd3c0f"
      },
      "source": [
        "# 2. Initialize Git, then Pull the Branch:\n",
        "! git config --global user.email $m\n",
        "! git config --global user.name $u\n",
        "! git init\n",
        "! git remote add origin https://$u:$p@github.com/pandov/mafia.git\n",
        "! git pull origin $b"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 731 (delta 42), reused 66 (delta 37), pack-reused 648\u001b[K\n",
            "Receiving objects: 100% (731/731), 38.44 MiB | 19.15 MiB/s, done.\n",
            "Resolving deltas: 100% (267/267), done.\n",
            "From https://github.com/pandov/mafia\n",
            " * branch            sound      -> FETCH_HEAD\n",
            " * [new branch]      sound      -> origin/sound\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqXEjuyF0nDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41221fa5-5c9d-4ff9-ad94-dab76af2873e"
      },
      "source": [
        "# 3. Run helper:\n",
        "! sh colab.sh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dvc==0.92.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/75/2f2a1e2ddbce43fd428766df925a4e2303c58b6d61e52e422ff509269837/dvc-0.92.1-py2.py3-none-any.whl (327kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 471kB/s \n",
            "\u001b[?25hCollecting pydrive2==1.4.9\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/fe/d4e8085f898cccee1c545ea198139bd58a4e8fe597d2c64540c954561618/PyDrive2-1.4.9-py2.py3-none-any.whl\n",
            "Collecting catalyst==20.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/cb/10860c15a9226728f14a5243e99e8399c6a5735b29f465bc91f3a2a29d34/catalyst-20.4.1-py2.py3-none-any.whl (326kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 38.3MB/s \n",
            "\u001b[?25hCollecting alchemy==20.4\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/d0/29085429e2f6203ee206a4aa93cb20cdafbdc2aa649d7b20de24eeb7fb69/alchemy-20.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.6/dist-packages (from dvc==0.92.1) (20.3)\n",
            "Collecting zc.lockfile>=1.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/2a/268389776288f0f26c7272c70c36c96dcc0bdb88ab6216ea18e19df1fadd/zc.lockfile-2.0-py2.py3-none-any.whl\n",
            "Collecting networkx<2.4,>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 36.7MB/s \n",
            "\u001b[?25hCollecting grandalf==0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/54/f4/a0b6a4c6d616d0a838b2dd0bc7bf74d73e8e8cdc880bab7fdb5fdc3d0e06/grandalf-0.6-py3-none-any.whl\n",
            "Collecting jsonpath-ng>=1.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/85/24/981fa76e1e415bcceb3a9741d5be04b32c10edd42d88f6783faa750b1239/jsonpath-ng-1.5.1.tar.gz\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from dvc==0.92.1) (46.1.3)\n",
            "Collecting PyYAML<5.4,>=5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 35.2MB/s \n",
            "\u001b[?25hCollecting requests>=2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[?25hCollecting texttable>=0.5.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ec/b1/8a1c659ce288bf771d5b1c7cae318ada466f73bd0e16df8d86f27a2a3ee7/texttable-1.6.2-py2.py3-none-any.whl\n",
            "Collecting dpath<3,>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/60/3f/562b045ad2542ab1279bbc5a05a62511c1ea1d8b5987fb0a50ee78704621/dpath-2.0.1.tar.gz\n",
            "Collecting configobj>=5.0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting flufl.lock>=3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/68/393c148df629f90a919de653ebb967a8bd8c83d07d2bc3150ca0faff3940/flufl.lock-3.2.tar.gz\n",
            "Collecting tqdm<5,>=4.45.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[?25hCollecting treelib>=1.5.5\n",
            "  Downloading https://files.pythonhosted.org/packages/04/b0/2269c328abffbb63979f7143351a24a066776b87526d79956aea5018b80a/treelib-1.6.1.tar.gz\n",
            "Collecting gitpython>3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/1a/0df85d2bddbca33665d2148173d3281b290ac054b5f50163ea735740ac7b/GitPython-3.1.1-py3-none-any.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 37.4MB/s \n",
            "\u001b[?25hCollecting distro>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/b7/b3c4270a11414cb22c6352ebc7a83aaa3712043be29daa05018fd5a5c956/distro-1.5.0-py2.py3-none-any.whl\n",
            "Collecting voluptuous>=0.11.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/3b/fe531688c0d9e057fccc0bc9430c0a3d4b90e0d2f015326e659c2944e328/voluptuous-0.11.7.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hCollecting pygtrie==2.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/18/41/2e5cefc895a32d9ca0f3574bd0df09e53a697023579a93582bedc4eeac4d/pygtrie-2.3.2.tar.gz\n",
            "Collecting python-dateutil<2.8.1,>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 39.2MB/s \n",
            "\u001b[?25hCollecting ply>=3.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from dvc==0.92.1) (0.4.8)\n",
            "Collecting funcy>=1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: inflect<4,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from dvc==0.92.1) (2.1.0)\n",
            "Requirement already satisfied: humanize>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from dvc==0.92.1) (0.5.1)\n",
            "Collecting pathspec>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/d0/887c58853bd4b6ffc7aa9cdba4fc57d7b979b45888a6bd47e4568e1cf868/pathspec-0.8.0-py2.py3-none-any.whl\n",
            "Collecting flatten-json>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/a9/1e35abfc4726065f9692decb3c57cf379e5d5329befc6fa5a1ab835fffb8/flatten_json-0.1.7-py3-none-any.whl\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting appdirs>=1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from dvc==0.92.1) (1.3.0)\n",
            "Collecting ruamel.yaml>=0.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/92/59af3e38227b9cc14520bf1e59516d99ceca53e3b8448094248171e9432b/ruamel.yaml-0.16.10-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 40.5MB/s \n",
            "\u001b[?25hCollecting nanotime>=0.5.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/54/6d5924f59cf671326e7809f4b3f70fa8df535d67e952ad0b6fea02f52faf/nanotime-0.5.2.tar.gz\n",
            "Requirement already satisfied: google-api-python-client>=1.7.12 in /usr/local/lib/python3.6/dist-packages (from pydrive2==1.4.9) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive2==1.4.9) (4.1.3)\n",
            "Collecting pyOpenSSL>=19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (0.10.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (5.5.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (2.4.1)\n",
            "Collecting deprecation\n",
            "  Downloading https://files.pythonhosted.org/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (0.5.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (1.4.0)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (4.4.1)\n",
            "Collecting crc32c>=1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/82/f60248c01a8a23ae07bd4c43d78d69b20ffe324311db3b0785e391aa09d2/crc32c-2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (1.0.3)\n",
            "Collecting Pillow<7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (1.18.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (0.22.2.post1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (4.1.2.30)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (0.16.2)\n",
            "Requirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (2.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst==20.4.1) (3.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=19.0->dvc==0.92.1) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging>=19.0->dvc==0.92.1) (1.12.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx<2.4,>=2.1->dvc==0.92.1) (4.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from grandalf==0.6->dvc==0.92.1) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->dvc==0.92.1) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->dvc==0.92.1) (2.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->dvc==0.92.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->dvc==0.92.1) (1.24.3)\n",
            "Collecting atpublic\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/71/125eefdde54cf640eb2c22f868158fb0595fce1512c6c51201b105c44e63/atpublic-1.0.tar.gz\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/52/ca35448b56c53a079d3ffe18b1978c6e424f6d4df02404877094c89f5bfb/gitdb-4.0.4-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.8MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/77/4bcd63f362bcb6c8f4f06253c11f9772f64189bf08cf3f40c5ccbda9e561/ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 30.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.12->pydrive2==1.4.9) (1.7.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.12->pydrive2==1.4.9) (0.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.12->pydrive2==1.4.9) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.12->pydrive2==1.4.9) (0.0.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive2==1.4.9) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive2==1.4.9) (4.0)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/04/686efee2dcdd25aecf357992e7d9362f443eb182ecd623f882bc9f7a6bba/cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn->catalyst==20.4.1) (1.4.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.4.1) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.4.1) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.4.1) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.4.1) (2.1.3)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.4.1) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.4.1) (4.8.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst==20.4.1) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst==20.4.1) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst==20.4.1) (0.14.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->catalyst==20.4.1) (3.10.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->catalyst==20.4.1) (1.1.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.4.1) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.4.1) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.4.1) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.4.1) (0.34.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.4.1) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.4.1) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.4.1) (1.28.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst==20.4.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst==20.4.1) (0.10.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/27/b1/e379cfb7c07bbf8faee29c4a1a2469dbea525f047c2b454c4afdefa20a30/smmap-3.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.7.12->pydrive2==1.4.9) (3.1.1)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyOpenSSL>=19.1.0->pydrive2==1.4.9) (1.14.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst==20.4.1) (0.1.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst==20.4.1) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst==20.4.1) (0.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst==20.4.1) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyOpenSSL>=19.1.0->pydrive2==1.4.9) (2.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst==20.4.1) (3.1.0)\n",
            "Building wheels for collected packages: networkx, jsonpath-ng, PyYAML, dpath, configobj, flufl.lock, treelib, voluptuous, pygtrie, funcy, nanotime, atpublic\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556408 sha256=9e37603d562f48d8ab6925fa003913514f05946950b0c362e10b98d59153f0a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\n",
            "  Building wheel for jsonpath-ng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonpath-ng: filename=jsonpath_ng-1.5.1-cp36-none-any.whl size=23919 sha256=a99f955ccf17910f303d4c7cc3ba5dd5ae442937d7a04c6403afe6bab40374e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/e6/94/298d44da8cc99fca216343afc8d877348146d583beac99ec49\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=5b5347406ebf30c1d6d683fedab4fd16a789657637d5e8f9039e2725e3e05bf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for dpath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dpath: filename=dpath-2.0.1-cp36-none-any.whl size=15139 sha256=bd6a04fbf06ef981480bd2ce9bc20690a7bcc5bf90b47374fd2318b09b8b98cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/0b/f5/0c40bd93ea28c6dd6a302f2861adc330e9cf3fe99ebfefe797\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=3f5c8d2b46708d397810820805e72d1b851926c127b1a54e28aab66cced3c8ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
            "  Building wheel for flufl.lock (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flufl.lock: filename=flufl.lock-3.2-cp36-none-any.whl size=19930 sha256=40cc3775b59ff9034e302d3d769d11351c32e1f7a724eafa72bace6477c0a7b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/51/d7/f65a7b7f37da7594f7021b122fe677187667ad21f1171d2514\n",
            "  Building wheel for treelib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treelib: filename=treelib-1.6.1-cp36-none-any.whl size=18370 sha256=717a800b9a9701a50e37734df172afd4f23de35a470b2ee5d22c0f90fc6fe7ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/1d/92/c50ec52951ccebafb40f3b8f0beb28fbaf745431c14a17c497\n",
            "  Building wheel for voluptuous (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for voluptuous: filename=voluptuous-0.11.7-cp36-none-any.whl size=28749 sha256=36b012c411be20d9b7a70522c9a8656baec558d9c62b19eb4e3d1cbe5e9007ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/e3/d0/a2d476b9cd09b8f5979789e0aaf07119726a3cfb19ee67aa1e\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygtrie: filename=pygtrie-2.3.2-cp36-none-any.whl size=18867 sha256=98f77b314e42587cd90fd71569dc858a5b954fe51ff23d08488de959fa35b3a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/10/3c/2d28c8ac56cda265d0c16ca129f50e5c3526f49a7fbe224cd9\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=5c12403b8a65e9892a0b53a31490ab87b2c8745e902f482da670973e4e8ee5b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "  Building wheel for nanotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nanotime: filename=nanotime-0.5.2-cp36-none-any.whl size=2442 sha256=05e5f1bd4c0ca63e2231f6ed592a463e8673e4dcd7d4f70542eaf9c30b547019\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/99/17/7135f635215e1f61e906295afd11f4f791cfe4ab45f3bfdca2\n",
            "  Building wheel for atpublic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atpublic: filename=atpublic-1.0-cp36-none-any.whl size=4505 sha256=114071400d7528b965b04f4866d37b69469b10e8370045d4da9aab6fa8ef0bb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/5d/fb4b06bb9bb028e49b117b9bdb93c9875e751ff52f6b08aa27\n",
            "Successfully built networkx jsonpath-ng PyYAML dpath configobj flufl.lock treelib voluptuous pygtrie funcy nanotime atpublic\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: alchemy 20.4 has requirement requests==2.22.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: zc.lockfile, networkx, grandalf, ply, jsonpath-ng, PyYAML, requests, texttable, dpath, configobj, shortuuid, atpublic, flufl.lock, tqdm, treelib, smmap, gitdb, gitpython, distro, voluptuous, pygtrie, python-dateutil, funcy, pathspec, flatten-json, colorama, appdirs, ruamel.yaml.clib, ruamel.yaml, nanotime, dvc, cryptography, pyOpenSSL, pydrive2, deprecation, crc32c, Pillow, tensorboardX, catalyst, alchemy\n",
            "  Found existing installation: networkx 2.4\n",
            "    Uninstalling networkx-2.4:\n",
            "      Successfully uninstalled networkx-2.4\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: tqdm 4.38.0\n",
            "    Uninstalling tqdm-4.38.0:\n",
            "      Successfully uninstalled tqdm-4.38.0\n",
            "  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed Pillow-6.2.2 PyYAML-5.3.1 alchemy-20.4 appdirs-1.4.3 atpublic-1.0 catalyst-20.4.1 colorama-0.4.3 configobj-5.0.6 crc32c-2.0 cryptography-2.9.2 deprecation-2.1.0 distro-1.5.0 dpath-2.0.1 dvc-0.92.1 flatten-json-0.1.7 flufl.lock-3.2 funcy-1.14 gitdb-4.0.4 gitpython-3.1.1 grandalf-0.6 jsonpath-ng-1.5.1 nanotime-0.5.2 networkx-2.3 pathspec-0.8.0 ply-3.11 pyOpenSSL-19.1.0 pydrive2-1.4.9 pygtrie-2.3.2 python-dateutil-2.8.0 requests-2.23.0 ruamel.yaml-0.16.10 ruamel.yaml.clib-0.2.0 shortuuid-1.0.1 smmap-3.0.2 tensorboardX-2.0 texttable-1.6.2 tqdm-4.45.0 treelib-1.6.1 voluptuous-0.11.7 zc.lockfile-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fADRpG_yYaNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load numpy.zip here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFyuQf0P0nKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4b051ed9-2d2a-4307-890e-a594517301eb"
      },
      "source": [
        "!unzip numpy -d data/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  numpy.zip\n",
            "   creating: data/numpy/\n",
            "   creating: data/numpy/Sound_RNN_test/\n",
            "  inflating: data/numpy/Sound_RNN_test/classes.npy  \n",
            "  inflating: data/numpy/Sound_RNN_test/classes_T.npy  \n",
            "  inflating: data/numpy/Sound_RNN_test/features.npy  \n",
            "  inflating: data/numpy/Sound_RNN_test/features_T.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v45K6Cqhz3kT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v5IpUGzz3kY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('origin_markup.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   ID  DATASET  GAME  ROUND  PLAYER_ID  CLASS  RATING_VIDEO  RATING_AUDIO  \\\n0   0        1     1      1          1      1             9             0   \n1   1        1     1      1          2      1            10             0   \n2   2        1     1      1          3      0             9             0   \n3   3        1     1      1          4      0            10             0   \n4   4        1     1      1          5      0             9             0   \n\n   START   END  \n0    0.0  16.0  \n1    0.0   0.0  \n2    0.0   0.0  \n3    0.0   0.0  \n4    3.0   0.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>DATASET</th>\n      <th>GAME</th>\n      <th>ROUND</th>\n      <th>PLAYER_ID</th>\n      <th>CLASS</th>\n      <th>RATING_VIDEO</th>\n      <th>RATING_AUDIO</th>\n      <th>START</th>\n      <th>END</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Ui0Fmjz3ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! play audio\n",
        "# import os \n",
        "# os.system(f'aplay {audio}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import librosa \n",
        "import matplotlib.pyplot as plt \n",
        "import librosa.display\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def create_dataset_mfcc(path_dir: dir, dataframe: pd ):\n",
        "\n",
        "    # Возвращает датасет для последующей разбивки\n",
        "    \n",
        "    features = []\n",
        "    classes = []\n",
        "    df = dataframe.loc[:, ['ID', 'CLASS']].to_numpy()\n",
        "    for filename, class_maf in df:\n",
        "\n",
        "        true_name = str(filename) + '.wav'\n",
        "        input_name = os.path.join(path_dir, true_name)\n",
        "\n",
        "        if os.path.exists(input_name):    \n",
        "            print('%s.....OK' % true_name)\n",
        "        else:\n",
        "            print('not exist %s' % input_name)\n",
        "            continue\n",
        "        \n",
        "        x, sr = librosa.load( input_name )\n",
        "        mfcc = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=13)\n",
        "        mfcc = np.array(mfcc)            \n",
        "        mfcc.resize((13,1600))\n",
        "\n",
        "        features.append(mfcc.T)\n",
        "        classes.append(class_maf)\n",
        "\n",
        "    return np.asarray(features), np.array(classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "Re2lTr7Oz3ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! CREATE DATASET\n",
        "# import data_numpy\n",
        "\n",
        "path_dir='../data/interhim/AIMAF/audio'\n",
        "features_numpy, classes_numpy = create_dataset_mfcc(path_dir= path_dir, dataframe= df)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.wav.....OK\n1.wav.....OK\n2.wav.....OK\n3.wav.....OK\n4.wav.....OK\n5.wav.....OK\n6.wav.....OK\n7.wav.....OK\n8.wav.....OK\n9.wav.....OK\n10.wav.....OK\n11.wav.....OK\n12.wav.....OK\n13.wav.....OK\n14.wav.....OK\n15.wav.....OK\n18.wav.....OK\n19.wav.....OK\n20.wav.....OK\n21.wav.....OK\n22.wav.....OK\n23.wav.....OK\n24.wav.....OK\n25.wav.....OK\n26.wav.....OK\n27.wav.....OK\n28.wav.....OK\n29.wav.....OK\n31.wav.....OK\n32.wav.....OK\n33.wav.....OK\n34.wav.....OK\n35.wav.....OK\n36.wav.....OK\n37.wav.....OK\n38.wav.....OK\n39.wav.....OK\n40.wav.....OK\n41.wav.....OK\n42.wav.....OK\n43.wav.....OK\n44.wav.....OK\n45.wav.....OK\n46.wav.....OK\n47.wav.....OK\n48.wav.....OK\n49.wav.....OK\n50.wav.....OK\n51.wav.....OK\n52.wav.....OK\n53.wav.....OK\n54.wav.....OK\n55.wav.....OK\n56.wav.....OK\n57.wav.....OK\n58.wav.....OK\n59.wav.....OK\n60.wav.....OK\n61.wav.....OK\n62.wav.....OK\n63.wav.....OK\n64.wav.....OK\n65.wav.....OK\n66.wav.....OK\n67.wav.....OK\n70.wav.....OK\n71.wav.....OK\n72.wav.....OK\n73.wav.....OK\n74.wav.....OK\n75.wav.....OK\n76.wav.....OK\n77.wav.....OK\n78.wav.....OK\n79.wav.....OK\n80.wav.....OK\n81.wav.....OK\n82.wav.....OK\n83.wav.....OK\n84.wav.....OK\n86.wav.....OK\n87.wav.....OK\n88.wav.....OK\n89.wav.....OK\n90.wav.....OK\n91.wav.....OK\n92.wav.....OK\n93.wav.....OK\n94.wav.....OK\n95.wav.....OK\n96.wav.....OK\n98.wav.....OK\n99.wav.....OK\n100.wav.....OK\n101.wav.....OK\n102.wav.....OK\n103.wav.....OK\n104.wav.....OK\n106.wav.....OK\n107.wav.....OK\n117.wav.....OK\n118.wav.....OK\n119.wav.....OK\n120.wav.....OK\n122.wav.....OK\n123.wav.....OK\n124.wav.....OK\n125.wav.....OK\n126.wav.....OK\n127.wav.....OK\n128.wav.....OK\n129.wav.....OK\n130.wav.....OK\n131.wav.....OK\n132.wav.....OK\n134.wav.....OK\n135.wav.....OK\n136.wav.....OK\n137.wav.....OK\n138.wav.....OK\n139.wav.....OK\n142.wav.....OK\n143.wav.....OK\n144.wav.....OK\n145.wav.....OK\n146.wav.....OK\n147.wav.....OK\n148.wav.....OK\n149.wav.....OK\n150.wav.....OK\n151.wav.....OK\n152.wav.....OK\n153.wav.....OK\n154.wav.....OK\n155.wav.....OK\n156.wav.....OK\n157.wav.....OK\n158.wav.....OK\n159.wav.....OK\n160.wav.....OK\n161.wav.....OK\n162.wav.....OK\n163.wav.....OK\n164.wav.....OK\n165.wav.....OK\n166.wav.....OK\n167.wav.....OK\n168.wav.....OK\n169.wav.....OK\n171.wav.....OK\n172.wav.....OK\n173.wav.....OK\n174.wav.....OK\n175.wav.....OK\n176.wav.....OK\n177.wav.....OK\n178.wav.....OK\n179.wav.....OK\n180.wav.....OK\n181.wav.....OK\n182.wav.....OK\n183.wav.....OK\n184.wav.....OK\n185.wav.....OK\n186.wav.....OK\n187.wav.....OK\n188.wav.....OK\n189.wav.....OK\n191.wav.....OK\n192.wav.....OK\n193.wav.....OK\n194.wav.....OK\n195.wav.....OK\n196.wav.....OK\n197.wav.....OK\n198.wav.....OK\n199.wav.....OK\n200.wav.....OK\n201.wav.....OK\n202.wav.....OK\n203.wav.....OK\n204.wav.....OK\n205.wav.....OK\n206.wav.....OK\n207.wav.....OK\n211.wav.....OK\n212.wav.....OK\n213.wav.....OK\n214.wav.....OK\n215.wav.....OK\n216.wav.....OK\n217.wav.....OK\n218.wav.....OK\n220.wav.....OK\n221.wav.....OK\n222.wav.....OK\n223.wav.....OK\n224.wav.....OK\n225.wav.....OK\n226.wav.....OK\n227.wav.....OK\n228.wav.....OK\n229.wav.....OK\n230.wav.....OK\n231.wav.....OK\n232.wav.....OK\n233.wav.....OK\n234.wav.....OK\n235.wav.....OK\n236.wav.....OK\n237.wav.....OK\n238.wav.....OK\n239.wav.....OK\n240.wav.....OK\n241.wav.....OK\n242.wav.....OK\n243.wav.....OK\n244.wav.....OK\n245.wav.....OK\n246.wav.....OK\n247.wav.....OK\n248.wav.....OK\n249.wav.....OK\n250.wav.....OK\n251.wav.....OK\n252.wav.....OK\n253.wav.....OK\n254.wav.....OK\n255.wav.....OK\n256.wav.....OK\n257.wav.....OK\n259.wav.....OK\n260.wav.....OK\n261.wav.....OK\n262.wav.....OK\n263.wav.....OK\n264.wav.....OK\n265.wav.....OK\n266.wav.....OK\n267.wav.....OK\n268.wav.....OK\n269.wav.....OK\n270.wav.....OK\n271.wav.....OK\n272.wav.....OK\n273.wav.....OK\n274.wav.....OK\n275.wav.....OK\n276.wav.....OK\n277.wav.....OK\n278.wav.....OK\n279.wav.....OK\n280.wav.....OK\n281.wav.....OK\n282.wav.....OK\n283.wav.....OK\n284.wav.....OK\n285.wav.....OK\n286.wav.....OK\n287.wav.....OK\n288.wav.....OK\n289.wav.....OK\n290.wav.....OK\n291.wav.....OK\n292.wav.....OK\n293.wav.....OK\n294.wav.....OK\n295.wav.....OK\n296.wav.....OK\n297.wav.....OK\n298.wav.....OK\n299.wav.....OK\n300.wav.....OK\n301.wav.....OK\n302.wav.....OK\n303.wav.....OK\n304.wav.....OK\n305.wav.....OK\n306.wav.....OK\n307.wav.....OK\n308.wav.....OK\n309.wav.....OK\n310.wav.....OK\n311.wav.....OK\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5ls8AOJz3kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import numpy as np\n",
        "#SAVE AND LOAD OUR DATA\n",
        "np.save('../data/processed/Sound_RNN_test/features_T.npy', features_numpy)\n",
        "# np.save('classes_T', classes_numpy)\n",
        "# features_numpy = np.load('data/numpy/Sound_RNN_test/features_T.npy')\n",
        "# classes_numpy = np.load('data/numpy/Sound_RNN_test/classes_T.npy')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U2rgQTzz3ks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "99e4f8a7-830f-4557-b128-e99e41cb40ee"
      },
      "source": [
        "print(features_numpy.shape)\n",
        "print(classes_numpy.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(284, 1600, 13)\n(284,)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K720R-kxz3kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train test split. Size of train data is 80% and size of test data is 20%. \n",
        "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
        "                                                                              classes_numpy,\n",
        "                                                                              test_size = 0.2,\n",
        "                                                                              random_state = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path1 = 'data/numpy/Sound_RNN_test/features_T.npy'\n",
        "path2 = 'data/numpy/Sound_RNN_test/classes_T.npy'\n",
        "Sound_RNN_test(path1, path2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cix-L6VYz3k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
        "featuresTrain = torch.from_numpy(features_train)\n",
        "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX2IvHtvz3k5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create feature and targets tensor for test set.\n",
        "featuresTest = torch.from_numpy(features_test)\n",
        "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr-bjZ7uz3k9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5092cee3-f122-402c-de1a-de9389377d9a"
      },
      "source": [
        "# Device\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "featuresTrain.to(device)\n",
        "targetsTrain.to(device)\n",
        "featuresTest.to(device)\n",
        "targetsTest.to(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHdU5yW0z3lB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# batch_size, epoch and iteration\n",
        "BATCH_SIZE = 12\n",
        "# n_iters = 1000\n",
        "# num_epochs = n_iters / (len(features_train) / batch_size)\n",
        "# num_epochs = int(num_epochs)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvM2aXjVz3lF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pytorch train and test sets\n",
        "# train = TensorDataset(featuresTrain,targetsTrain)\n",
        "# test = TensorDataset(featuresTest,targetsTest)\n",
        "\n",
        "path1 = 'data/processed/Sound_RNN_test/features_T.npy'\n",
        "path2 = 'data/processed/Sound_RNN_test/classes_T.npy'\n",
        "train = Sound_RNN_test(path1, path2)\n",
        "valid = Sound_RNN_test(path1, path2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aARdWR1Xz3lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data loader\n",
        "train_loader = DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
        "valid_loader = DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-UqesV2z3lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# параметры \n",
        "N_STEPS  =  3000\n",
        "N_INPUTS  =  20\n",
        "N_NEURONS  =  256\n",
        "N_OUTPUTS  =  2\n",
        "N_EPHOCS  =  21"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfINPYvvz3lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create RNN Model\n",
        "class AudioRNN(nn.Module):\n",
        "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
        "        super(AudioRNN, self).__init__()\n",
        "        \n",
        "        self.n_neurons = n_neurons\n",
        "        self.batch_size = batch_size\n",
        "        self.n_steps = n_steps\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_outputs = n_outputs\n",
        "        \n",
        "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
        "        \n",
        "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
        "        \n",
        "    def init_hidden(self,):\n",
        "        # (num_layers, batch_size, n_neurons)\n",
        "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
        "        \n",
        "    def forward(self, X):\n",
        "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
        "        X = X.permute(1, 0, 2) \n",
        "        \n",
        "        self.batch_size = X.size(1)\n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "        lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
        "        out = self.FC(self.hidden)\n",
        "        \n",
        "        return out.view(-1, self.n_outputs) # batch_size X n_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfnZHsxvz3lU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TESTING MODEL\n",
        "\n",
        "# dataiter = iter(train_loader)\n",
        "# audio, labels = dataiter.next()\n",
        "# model = AudioRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
        "# logits = model(audio.view(-1, 20,3000))\n",
        "# print(logits[0:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxDbKD_3z3lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Device\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model instance\n",
        "model = AudioRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# model.to(device)\n",
        "# criterion.to(device)\n",
        "\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsaxtIf8z3lb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "4efa3be5-5c67-488d-dabc-e3188c25b8f9"
      },
      "source": [
        "for epoch in range(N_EPHOCS):  # loop over the dataset multiple times\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    \n",
        "    # TRAINING ROUND\n",
        "    for i, data in enumerate(train_loader):\n",
        "         # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # reset hidden states\n",
        "        model.hidden = model.init_hidden() \n",
        "        \n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.view(-1, 3000,20) \n",
        "\n",
        "        # print(i)\n",
        "    \n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
        "         \n",
        "    model.eval()\n",
        "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f' \n",
        "          %(epoch, train_running_loss / (i+1), train_acc/(i+1)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 | Loss: 0.7047 | Train Accuracy: 55.77\n",
            "Epoch:  1 | Loss: 0.5560 | Train Accuracy: 70.51\n",
            "Epoch:  2 | Loss: 0.4995 | Train Accuracy: 75.00\n",
            "Epoch:  3 | Loss: 0.4455 | Train Accuracy: 71.79\n",
            "Epoch:  4 | Loss: 0.4045 | Train Accuracy: 80.13\n",
            "Epoch:  5 | Loss: 0.3880 | Train Accuracy: 78.85\n",
            "Epoch:  6 | Loss: 0.3467 | Train Accuracy: 83.33\n",
            "Epoch:  7 | Loss: 0.3048 | Train Accuracy: 82.69\n",
            "Epoch:  8 | Loss: 0.2900 | Train Accuracy: 83.97\n",
            "Epoch:  9 | Loss: 0.2308 | Train Accuracy: 87.18\n",
            "Epoch:  10 | Loss: 0.1859 | Train Accuracy: 91.03\n",
            "Epoch:  11 | Loss: 0.1423 | Train Accuracy: 92.95\n",
            "Epoch:  12 | Loss: 0.1535 | Train Accuracy: 91.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-973a4a6e6353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEnA5Jynz3lf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7a270615-9db8-4444-958c-80ad3988da3b"
      },
      "source": [
        "test_acc = 0.0\n",
        "for i, data in enumerate(test_loader):\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.view(-1, 3000, 20)\n",
        "\n",
        "    print(i)\n",
        "    outputs = model(inputs)\n",
        "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
        "    print(get_accuracy(outputs, labels, BATCH_SIZE))    \n",
        "\n",
        "print('Test Accuracy: %.2f'%( test_acc/(i+1)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "50.0\n",
            "1\n",
            "75.0\n",
            "2\n",
            "58.33333206176758\n",
            "3\n",
            "0.0\n",
            "Test Accuracy: 45.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEtOW0Gez3li",
        "colab_type": "code",
        "colab": {},
        "outputId": "336138b7-970d-446a-acd9-07b1b5ba71ab"
      },
      "source": [
        "# torch.save(model.state_dict(), 'model_state_dict.pt')\n",
        "# torch.save(model, 'all_model.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/mdmeldon/.local/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type AudioRNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pxqV6Ecz3ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model state dict load\n",
        "# model = TheModelClass(*args, **kwargs)\n",
        "# model.load_state_dict(torch.load(PATH))\n",
        "# model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggsek8GJz3lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model class must be defined somewhere\n",
        "# model = torch.load(PATH)\n",
        "# model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.8.2-final"
    },
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python38264bitvenvvenvcd0bc698e0d940a5bd5187da6b5fcb4c",
      "display_name": "Python 3.8.2 64-bit ('venv': venv)"
    },
    "colab": {
      "name": "Sound_RNN_test.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}